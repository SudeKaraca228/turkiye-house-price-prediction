{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6bce9fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"../data/processed/cleaned_data_after_eda.csv\")\n",
    "df.head()\n",
    "df = df.drop(columns = [\"Yatırıma_Uygunluk\",\"Takas\",\"Eşya_Durumu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "96da3eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_27016\\2051741078.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df = df[~room_noise]\n"
     ]
    }
   ],
   "source": [
    "df[\"Fiyat\"] = np.expm1(df[\"Fiyat\"])\n",
    "\n",
    "# df = df.drop(columns = [\"\"])\n",
    "condition_to_remove1 = (df[\"Net_Metrekare\"] > 300) & (df[\"Fiyat\"] < 2500000)\n",
    "condition_to_remove2 = (df[\"Net_Metrekare\"] < 100) & (df[\"Fiyat\"] > 10000000)\n",
    "condition_to_remove3 = (df[\"Fiyat\"] < 500000)\n",
    "\n",
    "cond_cheap_large_house = (df['Oda_Sayısı'] >= 5) & (df[\"Fiyat\"] < 1500000)\n",
    "cond_expensive_small_house = (df['Oda_Sayısı'] <= 2) & (df[\"Fiyat\"] > 8000000)\n",
    "cond_absolute_floor = (df[\"Fiyat\"] < 500000)\n",
    "\n",
    "noise_filter1 = condition_to_remove1 | condition_to_remove2 | condition_to_remove3\n",
    "room_noise = cond_cheap_large_house | cond_expensive_small_house | cond_absolute_floor\n",
    "df = df[~noise_filter1]\n",
    "df = df[~room_noise]\n",
    "# for col in numerical_columns:\n",
    "\n",
    "#     df.boxplot(column = col)\n",
    "#     plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec479d8",
   "metadata": {},
   "source": [
    "## CatBoost Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "566a7ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "df[\"Fiyat\"] = np.log1p(df[\"Fiyat\"])\n",
    "y1 = df[\"Fiyat\"]\n",
    "x1 = df.drop(\"Fiyat\", axis=1)\n",
    "cat_columns = np.where(x1.dtypes != float)[0]\n",
    "\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x1,y1,test_size=0.2,random_state=34,stratify=None)\n",
    "\n",
    "\n",
    "model_pipeline1 = Pipeline(steps =[(\"model\",CatBoostRegressor(cat_features=cat_columns,loss_function='RMSE', verbose=0,random_state=42, thread_count=-1))])\n",
    "# log_model = TransformedTargetRegressor(\n",
    "#     regressor=model_pipeline1,\n",
    "#     func=np.log1p,\n",
    "#     inverse_func=np.expm1\n",
    "# )\n",
    "\n",
    "# model_pipeline1.fit(x_train1, y_train1)\n",
    "\n",
    "# y_predict1 = model_pipeline1.predict(x_test1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe47e6eb",
   "metadata": {},
   "source": [
    "## CatBoost Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "65eec2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "# rmse1 = np.sqrt(mean_squared_error(y_test1,y_predict1))\n",
    "# mae1 = mean_absolute_error(y_test1,y_predict1)\n",
    "# r21 = r2_score(y_test1,y_predict1)\n",
    "\n",
    "# train_score1 = model_pipeline1.score(x_train1,y_train1)\n",
    "# test_score1 = model_pipeline1.score(x_test1,y_test1)\n",
    "\n",
    "# print(f\"RMSE: {rmse1:.2f}\") \n",
    "# print(f\"MAE:  {mae1:.2f}\")\n",
    "# print(f\"R2:   {r21:.2f}\")\n",
    "\n",
    "# print(f\"Training R2: %{train_score1*100:.2f}\")\n",
    "# print(f\"Testing R2:  %{test_score1*100:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfa77a8",
   "metadata": {},
   "source": [
    "## Data Encoding for The Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4b5c4b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "\n",
    "# y2 = df[\"Fiyat\"]\n",
    "# x2 = df.drop(\"Fiyat\", axis=1)\n",
    "\n",
    "\n",
    "# x_train2, x_test2, y_train2, y_test2 = train_test_split(x2,y2,test_size=0.2,random_state=65,stratify=None)\n",
    "\n",
    "# cat_columns= (df.select_dtypes(include=[\"object\"])).columns\n",
    "\n",
    "# ordinal_cols = [col for col in cat_columns if col != \"Şehir\"]\n",
    "\n",
    "\n",
    "# rf_ct = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#     ('target_enc', TargetEncoder(), [\"Şehir\"]),\n",
    "#     (\"encoder\",OrdinalEncoder(),ordinal_cols)\n",
    "#     ],\n",
    "#     remainder=\"passthrough\"\n",
    "# )\n",
    "\n",
    "# model_pipeline2 = Pipeline(steps=[\n",
    "#     (\"transformer\", rf_ct),\n",
    "#     (\"model\",RandomForestRegressor(random_state=34))\n",
    "# ])\n",
    "\n",
    "\n",
    "# model_pipeline2.fit(x_train2,y_train2)\n",
    "# y_predict2 =model_pipeline2.predict(x_test2)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330221ae",
   "metadata": {},
   "source": [
    "## Random Forest Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "4cf57ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse2 = np.sqrt(mean_squared_error(y_test2,y_predict2))\n",
    "# mae2 = mean_absolute_error(y_test2,y_predict2)\n",
    "# r22 = r2_score(y_test2,y_predict2)\n",
    "\n",
    "# train_score2 = model_pipeline2.score(x_train2,y_train2)\n",
    "# test_score2 = model_pipeline2.score(x_test2,y_test2)\n",
    "\n",
    "# print(f\"RMSE: %{rmse2*100:.4f}\") \n",
    "# print(f\"MAE:  %{mae2*100:.4f}\")\n",
    "# print(f\"R2:   %{r22*100:.4f}\")\n",
    "\n",
    "# print(f\"Training R2: %{train_score2*100:.4f}\")\n",
    "# print(f\"Testing R2:  %{test_score2*100:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90af8a98",
   "metadata": {},
   "source": [
    "## Tuning CatBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ff7191b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "param_dist = {\n",
    "  \n",
    "    'model__iterations': randint(500, 1500),          \n",
    "    'model__learning_rate': uniform(0.01, 0.2),          \n",
    "    'model__depth': randint(4, 10),                       \n",
    "    'model__l2_leaf_reg': uniform(1, 10),                \n",
    "    'model__border_count': [32, 64, 128, 254],           \n",
    "    'model__subsample': uniform(0.6, 0.4)                 \n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model_pipeline1,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    n_jobs=-1,     \n",
    "    cv=3,                  \n",
    "    scoring='neg_root_mean_squared_error',            \n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(x_train1, y_train1)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "y_train3 = best_model.predict(x_train1)\n",
    "y_predict3 = best_model.predict(x_test1)\n",
    "\n",
    "\n",
    "# rmse1 = np.sqrt(mean_squared_error(y_test1,y_predict3))\n",
    "# mae1 = mean_absolute_error(y_test1,y_predict3)\n",
    "# r21 = r2_score(y_test1,y_predict3)\n",
    "\n",
    "# train_score1 = model_pipeline1.score(x_train1,y_train1)\n",
    "# test_score1 = model_pipeline1.score(x_test1,y_test1)\n",
    "\n",
    "# print(f\"RMSE: %{rmse1*100:.2f}\") \n",
    "# print(f\"MAE:  %{mae1*100:.2f}\")\n",
    "# print(f\"R2:   %{r21*100:.2f}\")\n",
    "\n",
    "# print(f\"Training R2: %{train_score1*100:.2f}\")\n",
    "# print(f\"Testing R2:  %{test_score1*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c01bc3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.26\n",
      "MAE:  0.19\n",
      "R2:   0.66\n",
      "              Feature  Importance\n",
      "5               Şehir   27.831951\n",
      "0       Net_Metrekare   16.423043\n",
      "2       Bulunduğu_Kat    9.809917\n",
      "6  Binanın_Kat_Sayısı    9.379830\n",
      "4         Isıtma_Tipi    8.884589\n",
      "3        Binanın_Yaşı    8.616313\n",
      "8        Banyo_Sayısı    7.908909\n",
      "1          Oda_Sayısı    6.450530\n",
      "7     Kullanım_Durumu    4.694918\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Yüksek Giriş'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_27016\\2584044497.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     22\u001b[39m }).sort_values(\"Importance\", ascending=False)\n\u001b[32m     23\u001b[39m \n\u001b[32m     24\u001b[39m print(importance_df.head(\u001b[32m20\u001b[39m))\n\u001b[32m     25\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m r2_train = r2_score(x_train1, y_train3)\n\u001b[32m     27\u001b[39m r2_test  = r2_score(x_test1,y_test1)\n\u001b[32m     28\u001b[39m \n\u001b[32m     29\u001b[39m print(\u001b[33m\"Train R2:\"\u001b[39m, r2_train)\n",
      "\u001b[32mc:\\anaconda\\envs\\housing\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    215\u001b[39m                         prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m                     )\n\u001b[32m    217\u001b[39m                 ):\n\u001b[32m    218\u001b[39m                     \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m                 \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m                 \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m                 \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n",
      "\u001b[32mc:\\anaconda\\envs\\housing\\Lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[39m\n\u001b[32m   1272\u001b[39m         y_true, y_pred, sample_weight, multioutput\n\u001b[32m   1273\u001b[39m     )\n\u001b[32m   1274\u001b[39m \n\u001b[32m   1275\u001b[39m     _, y_true, y_pred, sample_weight, multioutput = (\n\u001b[32m-> \u001b[39m\u001b[32m1276\u001b[39m         _check_reg_targets_with_floating_dtype(\n\u001b[32m   1277\u001b[39m             y_true, y_pred, sample_weight, multioutput, xp=xp\n\u001b[32m   1278\u001b[39m         )\n\u001b[32m   1279\u001b[39m     )\n",
      "\u001b[32mc:\\anaconda\\envs\\housing\\Lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput, xp)\u001b[39m\n\u001b[32m    205\u001b[39m         correct keyword.\n\u001b[32m    206\u001b[39m     \"\"\"\n\u001b[32m    207\u001b[39m     dtype_name = _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp=xp)\n\u001b[32m    208\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     y_type, y_true, y_pred, sample_weight, multioutput = _check_reg_targets(\n\u001b[32m    210\u001b[39m         y_true, y_pred, sample_weight, multioutput, dtype=dtype_name, xp=xp\n\u001b[32m    211\u001b[39m     )\n\u001b[32m    212\u001b[39m \n",
      "\u001b[32mc:\\anaconda\\envs\\housing\\Lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput, dtype, xp)\u001b[39m\n\u001b[32m    111\u001b[39m     \"\"\"\n\u001b[32m    112\u001b[39m     xp, _ = get_namespace(y_true, y_pred, multioutput, xp=xp)\n\u001b[32m    113\u001b[39m \n\u001b[32m    114\u001b[39m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     y_true = check_array(y_true, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=dtype)\n\u001b[32m    116\u001b[39m     y_pred = check_array(y_pred, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=dtype)\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    118\u001b[39m         sample_weight = _check_sample_weight(sample_weight, y_true, dtype=dtype)\n",
      "\u001b[32mc:\\anaconda\\envs\\housing\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1050\u001b[39m                         )\n\u001b[32m   1051\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1052\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1053\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1055\u001b[39m                 raise ValueError(\n\u001b[32m   1056\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1057\u001b[39m                 ) from complex_warning\n",
      "\u001b[32mc:\\anaconda\\envs\\housing\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    754\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    755\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    756\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    758\u001b[39m \n\u001b[32m    759\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    760\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32mc:\\anaconda\\envs\\housing\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2167\u001b[39m             )\n\u001b[32m   2168\u001b[39m         values = self._values\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2171\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2172\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2173\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2174\u001b[39m \n",
      "\u001b[31mValueError\u001b[39m: could not convert string to float: 'Yüksek Giriş'"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "rmse1 = np.sqrt(mean_squared_error(y_test1,y_predict3))\n",
    "mae1 = mean_absolute_error(y_test1,y_predict3)\n",
    "r21 = r2_score(y_test1,y_predict3)\n",
    "\n",
    "# train_score1 = y_predict3.score(x_train1,y_train1)\n",
    "# test_score1 = y_predict3.score(x_test1,y_test1)\n",
    "\n",
    "print(f\"RMSE: {rmse1:.2f}\") \n",
    "print(f\"MAE:  {mae1:.2f}\")\n",
    "print(f\"R2:   {r21:.2f}\")\n",
    "\n",
    "cat = best_model.named_steps[\"model\"] \n",
    "importances = cat.get_feature_importance()\n",
    "feature_names = cat.feature_names_    \n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": importances\n",
    "}).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "print(importance_df.head(20))\n",
    "\n",
    "r2_train = r2_score(x_train1, y_train3)\n",
    "r2_test  = r2_score(x_test1,y_test1)\n",
    "\n",
    "print(\"Train R2:\", r2_train)\n",
    "print(\"Test R2:\", r2_test)\n",
    "print(f\"Training R2: %{r2_train*100:.2f}\")\n",
    "print(f\"Testing R2:  %{r2_test*100:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "housing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
